{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rYfyjjC-0IJJ",
        "outputId": "adf9ff94-3337-417b-9cb8-0fb5b8fecbc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU in use: Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "[I 2025-05-06 19:28:21,428] A new study created in memory with name: no-name-f49e97f9-42d1-4c86-84c8-79ddb4b5e0b7\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:28:29,919] Trial 0 finished with value: 9.217378616333008 and parameters: {'seed': 3584, 'learning_rate': 4.9325833832067384e-05, 'lora_r': 12, 'lora_alpha': 31}. Best is trial 0 with value: 9.217378616333008.\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:28:35,290] Trial 1 finished with value: 11.07805347442627 and parameters: {'seed': 6468, 'learning_rate': 4.887747378278119e-05, 'lora_r': 7, 'lora_alpha': 25}. Best is trial 0 with value: 9.217378616333008.\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:28:40,503] Trial 2 finished with value: 10.467657089233398 and parameters: {'seed': 6605, 'learning_rate': 2.1542714073893407e-05, 'lora_r': 9, 'lora_alpha': 18}. Best is trial 0 with value: 9.217378616333008.\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:28:45,742] Trial 3 finished with value: 11.589811325073242 and parameters: {'seed': 6939, 'learning_rate': 1.2365870475692727e-05, 'lora_r': 6, 'lora_alpha': 24}. Best is trial 0 with value: 9.217378616333008.\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:28:50,812] Trial 4 finished with value: 9.87341022491455 and parameters: {'seed': 827, 'learning_rate': 1.94858032914352e-05, 'lora_r': 6, 'lora_alpha': 30}. Best is trial 0 with value: 9.217378616333008.\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:28:55,807] Trial 5 finished with value: 9.8447904586792 and parameters: {'seed': 4555, 'learning_rate': 2.1506342423968602e-05, 'lora_r': 13, 'lora_alpha': 19}. Best is trial 0 with value: 9.217378616333008.\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:29:00,970] Trial 6 finished with value: 9.938972473144531 and parameters: {'seed': 5308, 'learning_rate': 3.200473280926155e-05, 'lora_r': 4, 'lora_alpha': 11}. Best is trial 0 with value: 9.217378616333008.\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:29:05,961] Trial 7 finished with value: 9.457006454467773 and parameters: {'seed': 1765, 'learning_rate': 3.506456280927527e-05, 'lora_r': 11, 'lora_alpha': 22}. Best is trial 0 with value: 9.217378616333008.\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:29:11,099] Trial 8 finished with value: 9.46103286743164 and parameters: {'seed': 4674, 'learning_rate': 4.702884324084798e-05, 'lora_r': 5, 'lora_alpha': 18}. Best is trial 0 with value: 9.217378616333008.\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:29:16,128] Trial 9 finished with value: 10.000483512878418 and parameters: {'seed': 2485, 'learning_rate': 2.986236480743948e-05, 'lora_r': 6, 'lora_alpha': 27}. Best is trial 0 with value: 9.217378616333008.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'seed': 3584, 'learning_rate': 4.9325833832067384e-05, 'lora_r': 12, 'lora_alpha': 31}\n",
            "Best Validation Loss: 9.217378616333008\n",
            "updating: best_t5_model/ (stored 0%)\n",
            "updating: best_t5_model/spiece.model (deflated 48%)\n",
            "updating: best_t5_model/special_tokens_map.json (deflated 85%)\n",
            "updating: best_t5_model/adapter_config.json (deflated 55%)\n",
            "updating: best_t5_model/tokenizer_config.json (deflated 94%)\n",
            "updating: best_t5_model/README.md (deflated 66%)\n",
            "updating: best_t5_model/adapter_model.safetensors (deflated 54%)\n",
            "updating: best_t5_model/added_tokens.json (deflated 83%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c602e03d-cbcc-4391-a548-d6cbc83a4533\", \"best_t5_model.zip\", 1243520)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install optuna transformers peft datasets accelerate --quiet\n",
        "!pip install sentencepiece --quiet\n",
        "\n",
        "# Imports\n",
        "import optuna\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from sklearn.metrics import f1_score\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU in use:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"Running on CPU\")\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:80%]\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess(example):\n",
        "    input_text = \"summarize: \" + example[\"article\"]\n",
        "    target_text = example[\"highlights\"]\n",
        "    inputs = tokenizer(input_text, max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "    targets = tokenizer(target_text, max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "    return {\n",
        "        \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
        "        \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
        "        \"labels\": targets[\"input_ids\"].squeeze()\n",
        "    }\n",
        "\n",
        "# Apply preprocessing\n",
        "processed_dataset = dataset.map(preprocess, remove_columns=dataset.column_names)\n",
        "\n",
        "# Objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Set random seed\n",
        "    seed = trial.suggest_int(\"seed\", 1, 9999)\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Hyperparameters\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5)\n",
        "    r = trial.suggest_int(\"lora_r\", 4, 16)\n",
        "    lora_alpha = trial.suggest_int(\"lora_alpha\", 8, 32)\n",
        "\n",
        "    # Load model\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Apply LoRA\n",
        "    peft_config = LoraConfig(\n",
        "        r=r,\n",
        "        lora_alpha=lora_alpha,\n",
        "        target_modules=[\"q\", \"v\"],\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM\n",
        "    )\n",
        "    model = get_peft_model(model, peft_config)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Training arguments\n",
        "    args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=4,\n",
        "        learning_rate=learning_rate,\n",
        "        save_strategy=\"no\",\n",
        "        logging_dir=\"./logs\",\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=processed_dataset.shuffle(seed=seed).select(range(100)),\n",
        "        eval_dataset=processed_dataset.shuffle(seed=seed+1).select(range(20)),\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    eval_loss = trainer.evaluate()[\"eval_loss\"]\n",
        "    return eval_loss\n",
        "\n",
        "# Run Optuna study\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "print(\"Best Validation Loss:\", study.best_value)\n",
        "\n",
        "# Save the best model\n",
        "best_config = LoraConfig(\n",
        "    r=study.best_params[\"lora_r\"],\n",
        "    lora_alpha=study.best_params[\"lora_alpha\"],\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM\n",
        ")\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "model = get_peft_model(model, best_config)\n",
        "model = model.to(device)\n",
        "\n",
        "model.save_pretrained(\"./best_t5_model\")\n",
        "tokenizer.save_pretrained(\"./best_t5_model\")\n",
        "\n",
        "# Zip and download\n",
        "!zip -r best_t5_model.zip ./best_t5_model\n",
        "from google.colab import files\n",
        "files.download(\"best_t5_model.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install optuna transformers peft datasets accelerate --quiet\n",
        "!pip install sentencepiece --quiet\n",
        "\n",
        "# Imports\n",
        "import optuna\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from sklearn.metrics import f1_score\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU in use:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"Running on CPU\")\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:80%]\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess(example):\n",
        "    input_text = \"summarize: \" + example[\"article\"]\n",
        "    target_text = example[\"highlights\"]\n",
        "    inputs = tokenizer(input_text, max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "    targets = tokenizer(target_text, max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "    return {\n",
        "        \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
        "        \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
        "        \"labels\": targets[\"input_ids\"].squeeze()\n",
        "    }\n",
        "\n",
        "# Apply preprocessing\n",
        "processed_dataset = dataset.map(preprocess, remove_columns=dataset.column_names)\n",
        "\n",
        "# Objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Set random seed\n",
        "    seed = trial.suggest_int(\"seed\", 1, 9999)\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Hyperparameters\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5)\n",
        "    r = trial.suggest_int(\"lora_r\", 4, 16)\n",
        "    lora_alpha = trial.suggest_int(\"lora_alpha\", 8, 32)\n",
        "\n",
        "    # Load model\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Apply LoRA\n",
        "    peft_config = LoraConfig(\n",
        "        r=r,\n",
        "        lora_alpha=lora_alpha,\n",
        "        target_modules=[\"q\", \"v\"],\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM\n",
        "    )\n",
        "    model = get_peft_model(model, peft_config)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Training arguments\n",
        "    args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=4,\n",
        "        learning_rate=learning_rate,\n",
        "        save_strategy=\"no\",\n",
        "        logging_dir=\"./logs\",\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=processed_dataset.shuffle(seed=seed).select(range(100)),\n",
        "        eval_dataset=processed_dataset.shuffle(seed=seed+1).select(range(20)),\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    eval_loss = trainer.evaluate()[\"eval_loss\"]\n",
        "    return eval_loss\n",
        "\n",
        "# Run Optuna study\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "print(\"Best Validation Loss:\", study.best_value)\n",
        "\n",
        "# Save the best model\n",
        "best_config = LoraConfig(\n",
        "    r=study.best_params[\"lora_r\"],\n",
        "    lora_alpha=study.best_params[\"lora_alpha\"],\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM\n",
        ")\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "model = get_peft_model(model, best_config)\n",
        "model = model.to(device)\n",
        "\n",
        "model.save_pretrained(\"./best_t5_model\")\n",
        "tokenizer.save_pretrained(\"./best_t5_model\")\n",
        "\n",
        "# Zip and download\n",
        "!zip -r best_t5_model.zip ./best_t5_model\n",
        "from google.colab import files\n",
        "files.download(\"best_t5_model.zip\")\n",
        "\n",
        "!pip install evaluate --quiet\n",
        "!pip install rouge_score\n",
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    vocab_size = tokenizer.vocab_size\n",
        "\n",
        "    def flatten_and_clean(lst):\n",
        "        flat = []\n",
        "        for token in lst:\n",
        "            if isinstance(token, (list, np.ndarray, torch.Tensor)):\n",
        "                flat.extend(flatten_and_clean(token))\n",
        "            else:\n",
        "                try:\n",
        "                    token = int(token)\n",
        "                    if 0 <= token < vocab_size:\n",
        "                        flat.append(token)\n",
        "                except:\n",
        "                    continue\n",
        "        return flat\n",
        "\n",
        "    cleaned_preds = [flatten_and_clean(p) for p in predictions]\n",
        "    cleaned_labels = [flatten_and_clean(l) for l in labels]\n",
        "\n",
        "    # Decode safely\n",
        "    decoded_preds = tokenizer.batch_decode(cleaned_preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(cleaned_labels, skip_special_tokens=True)\n",
        "\n",
        "    # Trim both lists to same length (smallest of the two)\n",
        "    n = min(len(decoded_preds), len(decoded_labels))\n",
        "    decoded_preds = decoded_preds[:n]\n",
        "    decoded_labels = decoded_labels[:n]\n",
        "\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [label.strip() for label in decoded_labels]\n",
        "\n",
        "    # Compute metrics\n",
        "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    bleu_result = bleu.compute(predictions=decoded_preds, references=[[label] for label in decoded_labels])\n",
        "\n",
        "    return {\n",
        "        \"rouge1\": rouge_result[\"rouge1\"],\n",
        "        \"rouge2\": rouge_result[\"rouge2\"],\n",
        "        \"rougeL\": rouge_result[\"rougeL\"],\n",
        "        \"bleu\": bleu_result[\"bleu\"]\n",
        "    }\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "print(\"Best Validation Loss:\", study.best_value)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    vocab_size = tokenizer.vocab_size\n",
        "\n",
        "    def flatten_and_clean(lst):\n",
        "        flat = []\n",
        "        for token in lst:\n",
        "            if isinstance(token, (list, np.ndarray, torch.Tensor)):\n",
        "                flat.extend(flatten_and_clean(token))\n",
        "            else:\n",
        "                try:\n",
        "                    token = int(token)\n",
        "                    if 0 <= token < vocab_size:\n",
        "                        flat.append(token)\n",
        "                except:\n",
        "                    continue\n",
        "        return flat\n",
        "\n",
        "    cleaned_preds = [flatten_and_clean(p) for p in predictions]\n",
        "    cleaned_labels = [flatten_and_clean(l) for l in labels]\n",
        "\n",
        "    # Decode safely\n",
        "    decoded_preds = tokenizer.batch_decode(cleaned_preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(cleaned_labels, skip_special_tokens=True)\n",
        "\n",
        "    # Trim both lists to same length (smallest of the two)\n",
        "    n = min(len(decoded_preds), len(decoded_labels))\n",
        "    decoded_preds = decoded_preds[:n]\n",
        "    decoded_labels = decoded_labels[:n]\n",
        "\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [label.strip() for label in decoded_labels]\n",
        "\n",
        "    # Compute metrics\n",
        "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    bleu_result = bleu.compute(predictions=decoded_preds, references=[[label] for label in decoded_labels])\n",
        "\n",
        "    return {\n",
        "        \"rouge1\": rouge_result[\"rouge1\"],\n",
        "        \"rouge2\": rouge_result[\"rouge2\"],\n",
        "        \"rougeL\": rouge_result[\"rougeL\"],\n",
        "        \"bleu\": bleu_result[\"bleu\"]\n",
        "    }\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    learning_rate=4.528513019349172e-05,  # from Optuna trial\n",
        "    save_strategy=\"no\",\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=processed_dataset.shuffle(seed=6680).select(range(100)),\n",
        "    eval_dataset=processed_dataset.shuffle(seed=6680 + 1).select(range(20)),\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "trainer.train()\n",
        "end = time.time()\n",
        "\n",
        "train_time = end - start\n",
        "print(f\"Training time: {train_time:.2f} seconds\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    max_memory = torch.cuda.max_memory_allocated() / 1e6  # convert bytes to MB\n",
        "    print(f\"Max GPU memory used: {max_memory:.2f} MB\")\n",
        "else:\n",
        "    max_memory = 0\n",
        "    print(\"CUDA not available. Skipping memory tracking.\")\n",
        "\n",
        "!pip install -U transformers --quiet\n",
        "\n",
        "# Objective function\n",
        "def objective(trial):\n",
        "    # Sample hyperparameters\n",
        "    seed = trial.suggest_int(\"seed\", 1, 9999)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5)\n",
        "    r = trial.suggest_int(\"lora_r\", 4, 16)\n",
        "    lora_alpha = trial.suggest_int(\"lora_alpha\", 8, 32)\n",
        "\n",
        "    # Set seeds\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Load model\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "    # Apply LoRA\n",
        "    peft_config = LoraConfig(\n",
        "        r=r,\n",
        "        lora_alpha=lora_alpha,\n",
        "        target_modules=[\"q\", \"v\"],\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM\n",
        "    )\n",
        "    model = get_peft_model(model, peft_config)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=4,\n",
        "        learning_rate=learning_rate,\n",
        "        save_strategy=\"no\",\n",
        "        logging_dir=\"./logs\",\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # Prepare trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=processed_dataset.shuffle(seed=seed).select(range(100)),\n",
        "        eval_dataset=processed_dataset.shuffle(seed=seed + 1).select(range(20)),\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Track time\n",
        "    start = time.time()\n",
        "    trainer.train()\n",
        "    end = time.time()\n",
        "    train_time = end - start\n",
        "    print(f\"Training time: {train_time:.2f} seconds\")\n",
        "\n",
        "    # GPU usage\n",
        "    if torch.cuda.is_available():\n",
        "        max_memory = torch.cuda.max_memory_allocated() / 1e6\n",
        "        print(f\"Max GPU memory used: {max_memory:.2f} MB\")\n",
        "    else:\n",
        "        max_memory = 0\n",
        "        print(\"CUDA not available.\")\n",
        "\n",
        "    # Evaluate\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    eval_loss = eval_metrics[\"eval_loss\"]\n",
        "\n",
        "    # Scalarized loss (tune lambda if needed)\n",
        "    lambda_weight = 0.0001\n",
        "    scalarized_objective = eval_loss + lambda_weight * train_time\n",
        "\n",
        "    print(f\"Eval Loss: {eval_loss:.4f}, Time: {train_time:.2f}s, Scalarized: {scalarized_objective:.4f}\")\n",
        "    return scalarized_objective\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "# Output best results\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "print(\"Best Validation Loss:\", study.best_value)\n",
        "\n",
        "import shutil\n",
        "shutil.make_archive('best_model_lora', 'zip', 'best_model_lora')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('best_model_lora.zip')\n",
        "\n",
        "# Install required packages\n",
        "!pip install optuna transformers peft datasets accelerate --quiet\n",
        "!pip install sentencepiece --quiet\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "# Load base model and tokenizer\n",
        "base_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"best_model_lora\")\n",
        "\n",
        "# Load fine-tuned LoRA adapter\n",
        "model = PeftModel.from_pretrained(base_model, \"best_model_lora\")\n",
        "model.eval()\n",
        "\n",
        "# Example input\n",
        "text = \"summarize: The US economy is facing challenges due to inflation and rate hikes.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Generate summary\n",
        "outputs = model.generate(**inputs, max_length=50, num_beams=4, early_stopping=True)\n",
        "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"ðŸ“ Summary:\", summary)"
      ],
      "metadata": {
        "id": "_49LIxNQ5ZvA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score\n",
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "bleu = evaluate.load(\"bleu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSctNrtq5ftm",
        "outputId": "bacad516-884f-47a2-8658-71f8095ed127"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "print(\"Best Validation Loss:\", study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ0c8VT26cII",
        "outputId": "6a2c5904-e9b9-4ce9-ff8a-1d7db2244d0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'seed': 3584, 'learning_rate': 4.9325833832067384e-05, 'lora_r': 12, 'lora_alpha': 31}\n",
            "Best Validation Loss: 9.217378616333008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    learning_rate=4.528513019349172e-05,  # from Optuna trial\n",
        "    save_strategy=\"no\",\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "2fo24hgE6N-R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=processed_dataset.shuffle(seed=6680).select(range(100)),\n",
        "    eval_dataset=processed_dataset.shuffle(seed=6680 + 1).select(range(20)),\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96HPx1O95vsS",
        "outputId": "bdc38116-c722-455f-94f1-b59fa063db38"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "trainer.train()\n",
        "end = time.time()\n",
        "\n",
        "train_time = end - start\n",
        "print(f\"Training time: {train_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "YWdGuoVi7Uzn",
        "outputId": "70ac8f9c-0ca5-436b-9a90-7024b991d503"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:05, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 6.80 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    max_memory = torch.cuda.max_memory_allocated() / 1e6  # convert bytes to MB\n",
        "    print(f\"Max GPU memory used: {max_memory:.2f} MB\")\n",
        "else:\n",
        "    max_memory = 0\n",
        "    print(\"CUDA not available. Skipping memory tracking.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw6qz7Fs7k71",
        "outputId": "8a1e38fb-c676-4de6-ff2d-230d1a140ab4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max GPU memory used: 1568.94 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers --quiet"
      ],
      "metadata": {
        "id": "YFgsUOuc-FY_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective function\n",
        "def objective(trial):\n",
        "    # Sample hyperparameters\n",
        "    seed = trial.suggest_int(\"seed\", 1, 9999)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5)\n",
        "    r = trial.suggest_int(\"lora_r\", 4, 16)\n",
        "    lora_alpha = trial.suggest_int(\"lora_alpha\", 8, 32)\n",
        "\n",
        "    # Set seeds\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Load model\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "    # Apply LoRA\n",
        "    peft_config = LoraConfig(\n",
        "        r=r,\n",
        "        lora_alpha=lora_alpha,\n",
        "        target_modules=[\"q\", \"v\"],\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM\n",
        "    )\n",
        "    model = get_peft_model(model, peft_config)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=4,\n",
        "        learning_rate=learning_rate,\n",
        "        save_strategy=\"no\",\n",
        "        logging_dir=\"./logs\",\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # Prepare trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=processed_dataset.shuffle(seed=seed).select(range(100)),\n",
        "        eval_dataset=processed_dataset.shuffle(seed=seed + 1).select(range(20)),\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Track time\n",
        "    start = time.time()\n",
        "    trainer.train()\n",
        "    end = time.time()\n",
        "    train_time = end - start\n",
        "    print(f\"Training time: {train_time:.2f} seconds\")\n",
        "\n",
        "    # GPU usage\n",
        "    if torch.cuda.is_available():\n",
        "        max_memory = torch.cuda.max_memory_allocated() / 1e6\n",
        "        print(f\"Max GPU memory used: {max_memory:.2f} MB\")\n",
        "    else:\n",
        "        max_memory = 0\n",
        "        print(\"CUDA not available.\")\n",
        "\n",
        "    # Evaluate\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    eval_loss = eval_metrics[\"eval_loss\"]\n",
        "\n",
        "    # Scalarized loss (tune lambda if needed)\n",
        "    lambda_weight = 0.0001\n",
        "    scalarized_objective = eval_loss + lambda_weight * train_time\n",
        "\n",
        "    print(f\"Eval Loss: {eval_loss:.4f}, Time: {train_time:.2f}s, Scalarized: {scalarized_objective:.4f}\")\n",
        "    return scalarized_objective\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "# Output best results\n",
        "print(\"Best Hyperparameters:\", study.best_params)\n",
        "print(\"Best Validation Loss:\", study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fSmZPRkb8pd5",
        "outputId": "6c26193a-e938-4c71-b487-232b9246dd5d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:41:31,464] A new study created in memory with name: no-name-109b959a-bfc6-458c-8395-9a875bef74d5\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 7.84 seconds\n",
            "Max GPU memory used: 2131.42 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:46:36,837] Trial 0 finished with value: 10.985109649920464 and parameters: {'seed': 8749, 'learning_rate': 1.7667252438765223e-05, 'lora_r': 13, 'lora_alpha': 20}. Best is trial 0 with value: 10.985109649920464.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 10.9843, Time: 7.84s, Scalarized: 10.9851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 4.28 seconds\n",
            "Max GPU memory used: 2131.42 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:51:38,428] Trial 1 finished with value: 9.44226360039711 and parameters: {'seed': 2287, 'learning_rate': 2.6406374650900043e-05, 'lora_r': 8, 'lora_alpha': 27}. Best is trial 1 with value: 9.44226360039711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 9.4418, Time: 4.28s, Scalarized: 9.4423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 4.26 seconds\n",
            "Max GPU memory used: 2131.42 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 19:56:38,908] Trial 2 finished with value: 10.336676637601853 and parameters: {'seed': 6525, 'learning_rate': 3.487395447154521e-05, 'lora_r': 5, 'lora_alpha': 19}. Best is trial 1 with value: 9.44226360039711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 10.3363, Time: 4.26s, Scalarized: 10.3367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 4.37 seconds\n",
            "Max GPU memory used: 2131.42 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 20:01:39,559] Trial 3 finished with value: 10.139937579584121 and parameters: {'seed': 2075, 'learning_rate': 1.5638347967361974e-05, 'lora_r': 4, 'lora_alpha': 15}. Best is trial 1 with value: 9.44226360039711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 10.1395, Time: 4.37s, Scalarized: 10.1399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 4.18 seconds\n",
            "Max GPU memory used: 2131.42 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 20:06:41,837] Trial 4 finished with value: 10.555175150108337 and parameters: {'seed': 6728, 'learning_rate': 1.141627876174082e-05, 'lora_r': 6, 'lora_alpha': 13}. Best is trial 1 with value: 9.44226360039711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 10.5548, Time: 4.18s, Scalarized: 10.5552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 4.16 seconds\n",
            "Max GPU memory used: 2131.42 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 20:11:42,411] Trial 5 finished with value: 10.32590690703392 and parameters: {'seed': 5428, 'learning_rate': 2.157256246229599e-05, 'lora_r': 12, 'lora_alpha': 17}. Best is trial 1 with value: 9.44226360039711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 10.3255, Time: 4.16s, Scalarized: 10.3259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 4.35 seconds\n",
            "Max GPU memory used: 2131.42 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 20:16:45,145] Trial 6 finished with value: 10.759498871541023 and parameters: {'seed': 6258, 'learning_rate': 3.061262870352042e-05, 'lora_r': 13, 'lora_alpha': 16}. Best is trial 1 with value: 9.44226360039711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 10.7591, Time: 4.35s, Scalarized: 10.7595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 4.24 seconds\n",
            "Max GPU memory used: 2131.42 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 20:21:54,618] Trial 7 finished with value: 12.029436410546303 and parameters: {'seed': 274, 'learning_rate': 3.6939998773275036e-05, 'lora_r': 5, 'lora_alpha': 26}. Best is trial 1 with value: 9.44226360039711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 12.0290, Time: 4.24s, Scalarized: 12.0294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 4.46 seconds\n",
            "Max GPU memory used: 2131.42 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 20:26:57,346] Trial 8 finished with value: 10.599328813099861 and parameters: {'seed': 4529, 'learning_rate': 1.874338483543256e-05, 'lora_r': 8, 'lora_alpha': 28}. Best is trial 1 with value: 9.44226360039711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 10.5989, Time: 4.46s, Scalarized: 10.5993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 4.28 seconds\n",
            "Max GPU memory used: 2133.30 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-06 20:31:58,646] Trial 9 finished with value: 11.335437957668304 and parameters: {'seed': 4165, 'learning_rate': 3.230649777601528e-05, 'lora_r': 16, 'lora_alpha': 26}. Best is trial 1 with value: 9.44226360039711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 11.3350, Time: 4.28s, Scalarized: 11.3354\n",
            "Best Hyperparameters: {'seed': 2287, 'learning_rate': 2.6406374650900043e-05, 'lora_r': 8, 'lora_alpha': 27}\n",
            "Best Validation Loss: 9.44226360039711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"best_model_lora\")\n",
        "tokenizer.save_pretrained(\"best_model_lora\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BffRAwAPWaJ8",
        "outputId": "9b45d694-705c-4c4f-bd52-51698c461db6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('best_model_lora/tokenizer_config.json',\n",
              " 'best_model_lora/special_tokens_map.json',\n",
              " 'best_model_lora/spiece.model',\n",
              " 'best_model_lora/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('best_model_lora', 'zip', 'best_model_lora')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h4lHEbUlWmtp",
        "outputId": "b27448b9-3282-4716-dd79-a8cf0bc92432"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/best_model_lora.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('best_model_lora.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-X5i8Xu6WnzJ",
        "outputId": "847dfe0e-05ac-4f84-e881-d8ea52a6c863"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ba4c88da-9ae5-4a1c-82d5-55679eabc640\", \"best_model_lora.zip\", 2066044)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install optuna transformers peft datasets accelerate --quiet\n",
        "!pip install sentencepiece --quiet"
      ],
      "metadata": {
        "id": "_-PWc34KZfm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install optuna transformers peft datasets accelerate --quiet\n",
        "!pip install sentencepiece --quiet\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "# Load base model and tokenizer\n",
        "base_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"best_model_lora\")\n",
        "\n",
        "# Load fine-tuned LoRA adapter\n",
        "model = PeftModel.from_pretrained(base_model, \"best_model_lora\")\n",
        "model.eval()\n",
        "\n",
        "# Example input\n",
        "text = \"summarize: The US economy is facing challenges due to inflation and rate hikes.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Generate summary\n",
        "outputs = model.generate(**inputs, max_length=50, num_beams=4, early_stopping=True)\n",
        "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"ðŸ“ Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0VnqxyZWwwK",
        "outputId": "5b8810fa-a46b-42f8-b62f-4698c96b88d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Summary: the economy is facing challenges due to inflation and rate hikes.\n"
          ]
        }
      ]
    }
  ]
}